{
  "scores": {
    "overall": 0.7212003602732083,
    "retrieval": {
      "context_precision": 0.6693749999705573,
      "context_recall": 0.6041666666666667,
      "context_relevance": 0.0
    },
    "generation": {
      "faithfulness": 0.7182271241830065,
      "answer_relevancy": 0.8930326502726027,
      "answer_correctness": 0.0
    }
  },
  "num_samples": 20,
  "timestamp": "2025-12-15T17:52:44.105304",
  "config": {
    "evaluator": "ragas",
    "model": "gpt-4o-mini"
  },
  "samples_detail": [
    {
      "question": "What is Docling and what is its primary purpose?",
      "answer": "Docling is an open-source, MIT-licensed Python package that converts PDF documents into structured JSON or Markdown. Its primary purpose is to turn static PDFs into machine-readable, richly structured...",
      "faithfulness": 0.4,
      "answer_relevancy": 0.9999999999999998,
      "context_precision": 0.9999999999,
      "context_recall": 0.0
    },
    {
      "question": "What document formats does Docling support?",
      "answer": "Input: PDF only.  \nOutput: JSON or Markdown.",
      "faithfulness": 0.6666666666666666,
      "answer_relevancy": 0.847036436242961,
      "context_precision": 0.0,
      "context_recall": 0.5
    },
    {
      "question": "How does Docling handle tables in documents?",
      "answer": "Docling detects tables in a PDF, runs the TableFormer vision-transformer model to recover their logical row/column structure (including headers, spans, and borderless layouts), maps the predicted stru...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9142176392831693,
      "context_precision": 0.99999999995,
      "context_recall": 1.0
    },
    {
      "question": "What OCR capabilities does Docling provide?",
      "answer": "Docling offers optional OCR powered by EasyOCR, suitable for scanned PDFs or embedded bitmap images. The feature can be toggled on/off, and by default feeds a 216-dpi page image to EasyOCR for accurat...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9629802992422103,
      "context_precision": 0.0,
      "context_recall": 0.3333333333333333
    },
    {
      "question": "What is RAG and why was it developed?",
      "answer": "RAG (Retrieval-Augmented Generation) is a neural architecture that augments sequence-to-sequence models with a non-parametric memory: a retriever fetches the most relevant Wikipedia passages for an in...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.903761093372019,
      "context_precision": 0.8874999999778125,
      "context_recall": 1.0
    },
    {
      "question": "What are the two main components of the RAG architecture?",
      "answer": "The two main components are:\n1. Retriever \u2013 fetches the most relevant passages for a given input.\n2. Generator \u2013 produces the target sequence by conditioning on both the input and the retrieved passag...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.8379095466764324,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "How does RAG reduce hallucinations in language models?",
      "answer": "RAG reduces hallucinations by conditioning generation on explicitly retrieved evidence passages rather than relying only on the knowledge stored in the model\u2019s parameters. By grounding each generated ...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9476732270600993,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is Dense Passage Retrieval (DPR) in the context of RAG?",
      "answer": "Dense Passage Retrieval (DPR) is the neural retriever used in RAG. It is a bi-encoder that independently embeds the input query and each candidate passage into dense vectors; at retrieval time it perf...",
      "faithfulness": 0.8,
      "answer_relevancy": 0.9844938712114106,
      "context_precision": 0.9999999999666667,
      "context_recall": 1.0
    },
    {
      "question": "What types of knowledge-intensive tasks does RAG excel at?",
      "answer": "RAG excels at knowledge-intensive NLP tasks that demand access to large amounts of external factual knowledge. These include (1) open-domain question answering\u2014where it sets state-of-the-art Exact-Mat...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9570057144227939,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is the difference between RAG-Sequence and RAG-Token models?",
      "answer": "RAG-Sequence uses the same retrieved document to generate the complete output sequence, whereas RAG-Token can select a different retrieved document for every target token, letting it combine informati...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9314425551536796,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "How does Docling handle document layout analysis?",
      "answer": "Docling handles document layout analysis with an RT-DETR object-detection model fine-tuned on DocLayNet. It ingests 72-dpi page images, runs inference via ONNX Runtime on a single CPU in under a secon...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.964587319683675,
      "context_precision": 0.94999999997625,
      "context_recall": 0.5
    },
    {
      "question": "What output formats can Docling generate?",
      "answer": "Docling can generate two output formats: JSON and Markdown.",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999999999999997,
      "context_precision": 0.8041666666465626,
      "context_recall": 0.0
    },
    {
      "question": "Why is chunking important in RAG pipelines?",
      "answer": "The provided sources do not explicitly mention chunking, so we can only infer its importance.  \nChunking (splitting documents into smaller passages) is critical in RAG because the retriever selects th...",
      "faithfulness": 0.5833333333333334,
      "answer_relevancy": 0.0,
      "context_precision": 0.19999999998,
      "context_recall": 0.0
    },
    {
      "question": "What advantages does RAG have over fine-tuning for domain adaptation?",
      "answer": "RAG offers four main advantages over standard fine-tuning when adapting to a new domain:\n\n1. Knowledge can be updated without re-training: because RAG leaves the parametric memory frozen and retrieves...",
      "faithfulness": 0.4117647058823529,
      "answer_relevancy": 0.9785942922186618,
      "context_precision": 0.6791666666496875,
      "context_recall": 0.75
    },
    {
      "question": "How does the retrieval component in RAG find relevant documents?",
      "answer": "RAG\u2019s retrieval component uses a dense-vector retriever (DPR). It embeds the input query and every candidate passage into fixed-size vectors; the most relevant passages are those whose vectors yield t...",
      "faithfulness": 0.5,
      "answer_relevancy": 0.9302109244947889,
      "context_precision": 0.249999999975,
      "context_recall": 0.0
    },
    {
      "question": "What role does the embedding model play in a RAG system?",
      "answer": "The embedding model supplies the vector representations that the retriever uses to identify the most relevant passages. It encodes both the incoming query and the pre-indexed documents into dense vect...",
      "faithfulness": 0.125,
      "answer_relevancy": 0.9470462917927842,
      "context_precision": 0.0,
      "context_recall": 0.6666666666666666
    },
    {
      "question": "How does Docling extract text from scanned PDF documents?",
      "answer": "Docling uses an optional OCR capability powered by EasyOCR. For each scanned PDF page, it renders a high-resolution bitmap (216 dpi) and passes that image to EasyOCR, which transcribes the text and re...",
      "faithfulness": 0.6666666666666666,
      "answer_relevancy": 0.918407739252185,
      "context_precision": 0.5833333333041666,
      "context_recall": 0.3333333333333333
    },
    {
      "question": "What is contextual chunking and why is it useful?",
      "answer": "Contextual chunking is the practice of splitting a document into segments that align with its inherent logical structure\u2014sections, paragraphs, tables, figures, references\u2014rather than using fixed-lengt...",
      "faithfulness": 0.1111111111111111,
      "answer_relevancy": 0.9145500559632656,
      "context_precision": 0.9999999999,
      "context_recall": 0.5
    },
    {
      "question": "What benchmarks were used to evaluate RAG in the original paper?",
      "answer": "The original RAG paper evaluated the model on four open-domain question-answering benchmarks: Natural Questions, TriviaQA, WebQuestions, and CuratedTrec.",
      "faithfulness": 0.2,
      "answer_relevancy": 0.9738309872902224,
      "context_precision": 0.3333333333,
      "context_recall": 0.5
    },
    {
      "question": "How does hybrid search improve RAG retrieval?",
      "answer": "RAG implements hybrid retrieval by coupling a dense-vector passage retriever (non-parametric memory) with a pre-trained seq-to-seq generator (parametric memory). The retriever fetches the top-K Wikipe...",
      "faithfulness": 0.9,
      "answer_relevancy": 0.9469050120916954,
      "context_precision": 0.699999999965,
      "context_recall": 1.0
    }
  ]
}