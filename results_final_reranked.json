{
  "scores": {
    "overall": 0.759417875253897,
    "retrieval": {
      "context_precision": 0.7254166666392672,
      "context_recall": 0.6458333333333333,
      "context_relevance": 0.0
    },
    "generation": {
      "faithfulness": 0.7300974025974026,
      "answer_relevancy": 0.9363240984455852,
      "answer_correctness": 0.0
    }
  },
  "num_samples": 20,
  "timestamp": "2025-12-15T19:54:01.188891",
  "config": {
    "evaluator": "ragas",
    "model": "gpt-4o-mini"
  },
  "samples_detail": [
    {
      "question": "What is Docling and what is its primary purpose?",
      "answer": "Docling is an open-source Python library that converts PDF documents into machine-readable JSON or Markdown. Its primary purpose is to make the text, layout, and tabular data trapped inside PDFs acces...",
      "faithfulness": 0.7142857142857143,
      "answer_relevancy": 0.9357250692752253,
      "context_precision": 0.3333333333,
      "context_recall": 0.0
    },
    {
      "question": "What document formats does Docling support?",
      "answer": "Docling accepts PDF documents as input and produces either JSON or Markdown as output.",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9493181170080812,
      "context_precision": 0.0,
      "context_recall": 0.0
    },
    {
      "question": "How does Docling handle tables in documents?",
      "answer": "Docling detects tables during page-level layout analysis and then runs each table through the TableFormer vision-transformer model. TableFormer receives an image crop of the table plus the already-ext...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9063714294415973,
      "context_precision": 0.8874999999778125,
      "context_recall": 1.0
    },
    {
      "question": "What OCR capabilities does Docling provide?",
      "answer": "Docling offers optional OCR powered by EasyOCR for scanned PDFs and embedded bitmaps. It defaults to 216-dpi page images for high detail, supports multiple languages, and can be enabled/disabled throu...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.909528093305983,
      "context_precision": 0.0,
      "context_recall": 0.5
    },
    {
      "question": "What is RAG and why was it developed?",
      "answer": "Retrieval-Augmented Generation (RAG) is a training and inference method that augments a parametric seq2seq language model with a non-parametric memory\u2014specifically, a dense vector index of Wikipedia a...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9161689130079249,
      "context_precision": 0.9166666666361111,
      "context_recall": 1.0
    },
    {
      "question": "What are the two main components of the RAG architecture?",
      "answer": "The two main components of the RAG architecture are:\n1. Retriever \u2013 retrieves relevant text passages given the input query.\n2. Generator \u2013 generates the output sequence conditioned on both the input a...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9774327964109168,
      "context_precision": 0.8666666666377778,
      "context_recall": 1.0
    },
    {
      "question": "How does RAG reduce hallucinations in language models?",
      "answer": "RAG reduces hallucinations by grounding every generation in retrieved, real-world passages (e.g., Wikipedia). Instead of relying solely on the parameters of a seq2seq model, RAG first fetches relevant...",
      "faithfulness": 0.75,
      "answer_relevancy": 0.9595890376040322,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is Dense Passage Retrieval (DPR) in the context of RAG?",
      "answer": "Dense Passage Retrieval (DPR) is the neural retriever used inside RAG. It is a bi-encoder that maps both the query and every passage in the knowledge base to fixed-size dense vectors. Given a question...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.984475684301139,
      "context_precision": 0.999999999975,
      "context_recall": 1.0
    },
    {
      "question": "What types of knowledge-intensive tasks does RAG excel at?",
      "answer": "RAG excels at three broad types of knowledge-intensive tasks:\n\n1. Open-domain question answering (e.g., Natural Questions, TriviaQA, WebQuestions, CuratedTrec), where it sets new state-of-the-art exac...",
      "faithfulness": 0.42857142857142855,
      "answer_relevancy": 0.960241193078915,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is the difference between RAG-Sequence and RAG-Token models?",
      "answer": "RAG-Sequence uses the same retrieved document to generate the whole output sequence; it treats that document as a single latent variable and marginalises over it once.  \nRAG-Token, by contrast, can pi...",
      "faithfulness": 0.9090909090909091,
      "answer_relevancy": 0.9313888359452601,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "How does Docling handle document layout analysis?",
      "answer": "Docling uses an RT-DETR object-detection model trained on DocLayNet to locate page elements. It processes 72-dpi images through ONNX Runtime on a CPU, filters overlapping detections by confidence and ...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.862323499332189,
      "context_precision": 0.99999999998,
      "context_recall": 0.5
    },
    {
      "question": "What output formats can Docling generate?",
      "answer": "Docling can produce two output formats: JSON and Markdown.",
      "faithfulness": 1.0,
      "answer_relevancy": 0.994878126764103,
      "context_precision": 0.999999999975,
      "context_recall": 0.0
    },
    {
      "question": "Why is chunking important in RAG pipelines?",
      "answer": "Chunking breaks the knowledge source into small, self-contained passages (here 100-word chunks) that become the atomic units of retrieval.  \nThis granularity lets the retriever pinpoint the specific f...",
      "faithfulness": 0.3333333333333333,
      "answer_relevancy": 0.8380095961523518,
      "context_precision": 0.699999999965,
      "context_recall": 0.5
    },
    {
      "question": "What advantages does RAG have over fine-tuning for domain adaptation?",
      "answer": "RAG allows \u201cindex hot-swapping\u201d: you can update the model\u2019s knowledge at test time by simply replacing its external Wikipedia index\u2014no retraining or gradient updates are needed. This makes domain adap...",
      "faithfulness": 0.8333333333333334,
      "answer_relevancy": 0.970408418055474,
      "context_precision": 0.999999999975,
      "context_recall": 0.75
    },
    {
      "question": "How does the retrieval component in RAG find relevant documents?",
      "answer": "The retrieval component uses DPR, a bi-encoder that embeds the input query and every document as dense vectors.  \nIt performs Maximum Inner-Product Search between the query vector and the document vec...",
      "faithfulness": 0.8,
      "answer_relevancy": 0.8914083774584057,
      "context_precision": 0.8874999999778125,
      "context_recall": 0.75
    },
    {
      "question": "What role does the embedding model play in a RAG system?",
      "answer": "In a RAG system the embedding models (implemented inside the Dense Passage Retriever) convert the input query and every candidate passage into dense vectors. These vectors allow the retriever to perfo...",
      "faithfulness": 0.3333333333333333,
      "answer_relevancy": 0.971402049299535,
      "context_precision": 0.0,
      "context_recall": 0.6666666666666666
    },
    {
      "question": "How does Docling extract text from scanned PDF documents?",
      "answer": "Docling extracts text from scanned PDFs by invoking its optional OCR module. It renders each page as a 216-dpi image and runs EasyOCR on that image to transcribe the text, making the content available...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9979130319491717,
      "context_precision": 0.4166666666458333,
      "context_recall": 0.25
    },
    {
      "question": "What is contextual chunking and why is it useful?",
      "answer": "Contextual chunking is the practice of splitting a document into segments so that each segment retains the surrounding structural and semantic context (headings, tables, captions, section boundaries)....",
      "faithfulness": 0.0,
      "answer_relevancy": 0.9999991006076095,
      "context_precision": 0.9999999999,
      "context_recall": 0.0
    },
    {
      "question": "What benchmarks were used to evaluate RAG in the original paper?",
      "answer": "Natural Questions (NQ), TriviaQA (TQA), WebQuestions (WQ), CuratedTrec (CT), Jeopardy, MSMARCO, FEVER-3, FEVER-2, and SearchQA.",
      "faithfulness": 0.3333333333333333,
      "answer_relevancy": 0.769900599913789,
      "context_precision": 0.99999999995,
      "context_recall": 1.0
    },
    {
      "question": "How does hybrid search improve RAG retrieval?",
      "answer": "Hybrid search improves RAG retrieval by letting the model choose between (or combine) a learned dense-vector retriever and a sparse BM25 retriever. For entity-centric data (e.g., FEVER claims) BM25\u2019s ...",
      "faithfulness": 0.16666666666666666,
      "answer_relevancy": 1.0,
      "context_precision": 0.49999999995,
      "context_recall": 1.0
    }
  ]
}