{
  "scores": {
    "overall": 0.8288758815132863,
    "retrieval": {
      "context_precision": 0.76916666663842,
      "context_recall": 0.7041666666666666,
      "context_relevance": 0.0
    },
    "generation": {
      "faithfulness": 0.9173295454545455,
      "answer_relevancy": 0.924840647293513,
      "answer_correctness": 0.0
    }
  },
  "num_samples": 20,
  "timestamp": "2025-12-17T12:44:14.888762",
  "config": {
    "evaluator": "ragas",
    "model": "gpt-4o-mini"
  },
  "samples_detail": [
    {
      "question": "What is Docling and what is its primary purpose?",
      "answer": "Docling is an open-source, MIT-licensed Python package designed for PDF document conversion. Its primary purpose is to convert PDF documents into machine-readable formats\u2014specifically JSON or Markdown...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.90355936048241,
      "context_precision": 0.32499999998375,
      "context_recall": 0.0
    },
    {
      "question": "What document formats does Docling support?",
      "answer": "Docling supports converting PDF documents into JSON and Markdown formats.",
      "faithfulness": 1.0,
      "answer_relevancy": 0.959405686128708,
      "context_precision": 0.0,
      "context_recall": 0.5
    },
    {
      "question": "How does Docling handle tables in documents?",
      "answer": "Docling handles tables in documents by using a specialized AI model called TableFormer for table structure recognition. Within its linear processing pipeline, after parsing the PDF and rendering page ...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999999999999998,
      "context_precision": 0.999999999975,
      "context_recall": 1.0
    },
    {
      "question": "What OCR capabilities does Docling provide?",
      "answer": "Docling provides optional OCR (Optical Character Recognition) capabilities. This feature is primarily designed to handle scanned PDF documents and bitmap images embedded within pages. In its initial r...",
      "faithfulness": 0.9090909090909091,
      "answer_relevancy": 0.9794477076114422,
      "context_precision": 0.49999999995,
      "context_recall": 0.5
    },
    {
      "question": "What is RAG and why was it developed?",
      "answer": "RAG stands for Retrieval-Augmented Generation. It is a model architecture that combines a pre-trained parametric memory (a sequence-to-sequence model like BART) with a non-parametric memory (a dense v...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9345630537323689,
      "context_precision": 0.8041666666465626,
      "context_recall": 1.0
    },
    {
      "question": "What are the two main components of the RAG architecture?",
      "answer": "The two main components of the RAG architecture are:\n1.  A **retriever** (p_\u03b7(z|x)), which retrieves relevant text documents given an input query.\n2.  A **generator** (p_\u03b8(y_i|x, z, y_1:i-1)), which i...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999999999999996,
      "context_precision": 0.9166666666361111,
      "context_recall": 1.0
    },
    {
      "question": "How does RAG reduce hallucinations in language models?",
      "answer": "RAG reduces hallucinations by grounding the language model's generations in retrieved, external factual knowledge. Instead of relying solely on its fixed, parametric memory, the model retrieves releva...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999999999999998,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is Dense Passage Retrieval (DPR) in the context of RAG?",
      "answer": "In the context of RAG, Dense Passage Retrieval (DPR) is the retrieval component based on a bi-encoder architecture. It encodes queries and documents into dense vector representations using BERTBASE en...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999999999999999,
      "context_precision": 0.699999999965,
      "context_recall": 1.0
    },
    {
      "question": "What types of knowledge-intensive tasks does RAG excel at?",
      "answer": "RAG excels at several knowledge-intensive tasks, including:\n1. **Open-domain question answering (QA)**: It achieves state-of-the-art results on benchmarks like Natural Questions, TriviaQA, WebQuestion...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9482304629784287,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "What is the difference between RAG-Sequence and RAG-Token models?",
      "answer": "The primary difference between RAG-Sequence and RAG-Token models lies in how they integrate retrieved documents during sequence generation.\n\n1.  **Document Usage per Sequence**: The RAG-Sequence model...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9827453780524074,
      "context_precision": 0.99999999998,
      "context_recall": 1.0
    },
    {
      "question": "How does Docling handle document layout analysis?",
      "answer": "Docling handles document layout analysis using a dedicated AI model. This model is an object detector based on the RT-DETR architecture, which has been retrained on the DocLayNet dataset and other pro...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999975491760056,
      "context_precision": 0.99999999998,
      "context_recall": 0.5
    },
    {
      "question": "What output formats can Docling generate?",
      "answer": "Docling can generate output in JSON or Markdown format.",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9847985494070056,
      "context_precision": 0.8874999999778125,
      "context_recall": 0.6666666666666666
    },
    {
      "question": "Why is chunking important in RAG pipelines?",
      "answer": "Based on the provided context from the RAG paper, there is no information discussing the importance of chunking in RAG pipelines. The context describes the retrieval and generation components, trainin...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.956738364618641,
      "context_precision": 0.99999999998,
      "context_recall": 0.5
    },
    {
      "question": "What advantages does RAG have over fine-tuning for domain adaptation?",
      "answer": "RAG has a significant advantage over standard fine-tuning for domain adaptation because it allows knowledge to be updated quickly and efficiently without retraining the model's parameters. Specificall...",
      "faithfulness": 0.6,
      "answer_relevancy": 0.9904146833898887,
      "context_precision": 0.99999999998,
      "context_recall": 0.5
    },
    {
      "question": "How does the retrieval component in RAG find relevant documents?",
      "answer": "The retrieval component in RAG finds relevant documents using a Dense Passage Retrieval (DPR) bi-encoder architecture. It encodes the input query and all documents in the knowledge source into dense v...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9999991133079901,
      "context_precision": 0.9999999999666667,
      "context_recall": 0.75
    },
    {
      "question": "What role does the embedding model play in a RAG system?",
      "answer": "In a RAG system, the embedding model plays a crucial role in the retriever component by encoding input queries and documents into dense vector representations. These embeddings allow the system to per...",
      "faithfulness": 0.4,
      "answer_relevancy": 0.9999999999999998,
      "context_precision": 0.0,
      "context_recall": 0.6666666666666666
    },
    {
      "question": "How does Docling extract text from scanned PDF documents?",
      "answer": "Docling extracts text from scanned PDF documents using its optional Optical Character Recognition (OCR) capability. This feature is specifically designed to handle scanned PDFs and embedded bitmap ima...",
      "faithfulness": 0.8333333333333334,
      "answer_relevancy": 0.9553456677667203,
      "context_precision": 0.7499999999625,
      "context_recall": 0.3333333333333333
    },
    {
      "question": "What is contextual chunking and why is it useful?",
      "answer": "Based on the provided context, \"contextual chunking\" refers to the process of splitting large knowledge source documents (specifically, Wikipedia articles in the RAG experiments) into smaller, disjoin...",
      "faithfulness": 0.6666666666666666,
      "answer_relevancy": 0.9210145588913489,
      "context_precision": 0.9999999999,
      "context_recall": 0.5
    },
    {
      "question": "What benchmarks were used to evaluate RAG in the original paper?",
      "answer": "In the original RAG paper, the models were evaluated on multiple benchmarks. The primary open-domain question answering benchmarks were:  \n1. **Natural Questions (NQ)**  \n2. **TriviaQA (TQA)**  \n3. **...",
      "faithfulness": 1.0,
      "answer_relevancy": 0.9805528103268965,
      "context_precision": 0.999999999975,
      "context_recall": 1.0
    },
    {
      "question": "How does hybrid search improve RAG retrieval?",
      "answer": "The provided context does not explicitly describe a \"hybrid search\" technique for improving retrieval within RAG. Instead, the RAG model itself is a **hybrid system** that combines parametric memory (...",
      "faithfulness": 0.9375,
      "answer_relevancy": 0.0,
      "context_precision": 0.49999999995,
      "context_recall": 0.6666666666666666
    }
  ]
}